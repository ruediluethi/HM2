\documentclass[11pt,a4paper]{book} 
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{verbatim}
\geometry{
  left=3cm,
  right=3cm,
  top=3cm,
  bottom=3cm,
  bindingoffset=0mm
}
\usepackage{enumerate}
\usepackage[T1]{fontenc} 
\usepackage{ucs}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{mdframed}

\newcommand {\Q}	{\mathbb{Q}}
\newcommand {\R}	{\mathbb{R}}
\newcommand {\C}	{\mathbb{C}}
\newcommand {\Rn}	{\mathbb{R}^n}
\newcommand {\Rm}	{\mathbb{R}^m}
\newcommand {\Rmn}	{\mathbb{R}^{m+n}}
\newcommand {\Rzwei}	{\mathbb{R}^2}
\newcommand {\Rnxn}	{\mathbb{R}^{n \times n}}
\newcommand {\Rmxn}	{\mathbb{R}^{m \times n}}
\newcommand {\Rmxm}	{\mathbb{R}^{m \times m}}
\newcommand {\Cn}	{\mathbb{C}^n}
\newcommand {\Cnxn}	{\mathbb{C}^{n \times n}}
\newcommand {\N}	{\mathbb{N}}
\newcommand{\1}    	{\mathbbm{1}}
\newcommand{\Onot}		{\mathcal{O}}
\newcommand{\diag}	{\textrm{diag}}
\newcommand{\mitt}	{\textrm{ mit }}
\newcommand{\fum}	{f^{-1}}

%\newcommand{\Beweis}		{\noindent\colorbox{lightgray}{\textcolor{white}{\textbf{Beweis:}}} \color{gray}}
%\newcommand{\OED}	{\color{black}}
\newcommand{\Beweis}[1][Beweis]
{\begin{mdframed}[backgroundcolor=gray!10,linewidth=0pt]\noindent\textit{\textbf{{#1}:}}~}
\newcommand{\OED}	{\end{mdframed}}

\newcommand{\Beispiel}[1][Anwendungsbeispiel]
{\begin{mdframed}[backgroundcolor=green!10,linewidth=0pt]\noindent\textit{\textbf{{#1}:}}~}
\newcommand{\Beispielende}	{\end{mdframed}}

\newcommand{\Bemerkung}	{\noindent\textit{Bemerkung}: }

\title{Höhere Mathematik II}
\author{Mitschrift der Vorlesung von Prof. Lehn\\im Sommersemester 2019 an der Uni Ulm}

\begin{document}

\maketitle
\tableofcontents 

\chapter*{Einführung}
\section{Stetigkeit in einer Dimension}
\begin{align*}
	f \textrm{ ist stetig in } x_0 & \\
	&\quad \Leftrightarrow \quad
	\lim_{x \rightarrow x_0} f(x) = f(x_0) \\
	&\quad \Leftrightarrow \quad
	\forall \left(x_n\right) \textrm{ mit } \lim_{n \rightarrow \infty} x_n = x_0
	\textrm{ gilt }  \lim_{n \rightarrow \infty} f(x_n) = f(x_0) \\
	&\quad \Leftrightarrow \quad \forall~ \varepsilon > 0 \quad \exists~ \delta \quad \textrm{mit} \quad \vert f(x) - f(x_0) \vert < \varepsilon \quad \forall~ x \in \left( x_0 - \delta, x_0 + \delta \right)
\end{align*}
\Bemerkung Der Grenzwert von Funktionen ist über den Grenzwert von Folgen definiert und kann auch nur so überprüft werden.

\section{Zwei Sonderfälle}
\subsection*{Skalarfeld}
Sei \( f : \Rzwei \rightarrow \R \) \\
Visualisierung durch Höhenlinien: \( H_c := \left\{ x \in \Rn : f(x) = c \right\} \) \\
Beispiel: \( f(x,y) = x^2 + y^2 \)

\subsection*{Vektorfeld}
Sei \( f : \Rzwei \rightarrow \Rzwei \) \\
Beispiel: \(f(x,y) = \left(\begin{array}{c} x \\ y \end{array} \right)\)

\chapter{Differentialrechnung in höheren Dimensionen}

\section{Topologie}

\subsubsection*{Skalarprodukt}
Definition: \( \left< x,y \right> := x^\top y = \sum_{k=1}^n x_k y_k \) für \(x,y \in \Rn\)

\subsubsection*{Euklidische Norm}
Definition: \( \Vert x \Vert_2 := \sqrt{\left< x,x \right>} = \sqrt{\sum_{k=1}^n x_k^2} \)

\subsection{Korollar}
Sei \(x \in \Rn\) mit \(x = \left(\begin{array}{c} x_1 \\ \vdots \\ x_n \end{array}\right)\)
\begin{enumerate}[1.~]
	\item \begin{align*}
		\max_{1 \leqslant k \leqslant n} \vert x_k \vert \leqslant \Vert x \Vert \leqslant \sqrt{n} \max_{1 \leqslant k \leqslant n} \vert x_k \vert
	\end{align*}
	\item Cauchy-Schwarz-Ungleichung:
	\begin{align*}
		\forall~ x,y \in \Rn \quad : \quad \vert \left< x,y \right> \vert \leqslant \Vert x \Vert \cdot \Vert y \Vert
	\end{align*}
	Begründung (nicht Beweis!) durch alternative Definition: \( \left< x,y \right> = \Vert x \Vert \cdot \Vert y \Vert \underbrace{\cos \alpha}_{\leqslant 1} \) \\
	Dabei ist \(\alpha\) der Winkel der zwischen \(x\) und \(y\) eingeschlossen wird. \\
	Daraus folgt:
	\begin{align*}
		\vert \left< x,y \right> \vert = \Vert x \Vert \cdot \Vert y \Vert
		\Leftrightarrow
		x,y \textrm{ sind lin. unabhängig} : x = \lambda y \textrm{ oder } y = \lambda x \textrm{ für } \lambda \in \R
	\end{align*}
	\item \(\Vert \cdot \Vert\) ist eine Norm. Eine Norm hat folgende Eigenschaften:
	\begin{enumerate}[(i)]
		\item \( \Vert x \Vert \geqslant 0 \) und \( \Vert x \Vert = 0 \Leftrightarrow x = 0 \)
		\item \( \Vert \lambda x \Vert = \vert \lambda \vert \cdot \Vert x \Vert  \)
		\item \( \Vert x + y \Vert \leqslant \Vert x \Vert  + \Vert y \Vert \) Dreiecksungleichung
	\end{enumerate}
\end{enumerate}

\subsection{Konvention}
Für \(A \subset \Rn\) gilt für das Komplement \(A^c = \Rn \setminus A\)

\subsection{Definition der \(\varepsilon\)-Umgebung}
Sei \(x_0 \in \Rn\) und \(\varepsilon > 0\), dann gilt für die \(\varepsilon\)-Umgebung \(U_\varepsilon(x_0)\) von \(x_0\):
\begin{align*}
	U_\varepsilon(x_0) := \left\{ x \in \Rn : \Vert x - x_0 \Vert < \varepsilon \right\}
\end{align*}
\Bemerkung Die punktierte \(\varepsilon\)-Umgebung ist definiert als: \( \dot{U}_\varepsilon = U_\varepsilon (a) \setminus \left\{ a \right\} \)

\subsection{Topologische Grundbegriffe}
Sei \(A \subset \Rn\), dann heißt ein Punkt \(x_0 \in \Rn\)
\begin{enumerate}[(i)]
	\item ein \textbf{innerer Punkt}, wenn gilt \(\exists~ \varepsilon > 0\) mit \(U_\varepsilon(x_0) \subset A\) \\
	Menge aller inneren Punkte: \( \mathring{A} = \left\{ x \in \Rn : \exists~ \varepsilon > 0 \textrm{ mit } U_\varepsilon(x) \subset A \right\} \)
	\item ein \textbf{Berührungspunkt}, wenn \(\forall~ \varepsilon > 0\) gilt \(U_\varepsilon (x_0) \cap A \neq \varnothing \) \\
	\textbf{abgeschlossene Hülle}: \(\overline{A} = \left\{ x \in \Rn : \forall~ \varepsilon > 0 \textrm{ gilt } U_\varepsilon(x_0) \neq \varnothing \right\} \)
	\item ein \textbf{Häufungspunkt}, wenn \(\forall~ \varepsilon > 0\) gilt \( \left( U_\varepsilon(x_0) \setminus \left\{ x_0 \right\} \right) \cap A \neq \varnothing \) \\
	Die Menge aller Häufungspunkte wird mit \(A'\) bezeichnet.
	\item ein \textbf{Randpunkt}, wenn \(\forall~ \varepsilon > 0\) gilt \( U_\varepsilon(x_0) \cap A \neq \varnothing\) und \( U_\varepsilon(x_0) \cap A^c \neq \varnothing\) \\
	Menge aller Randpunkte oder auch \textbf{Rand} von \(A\) wird mit \(\partial A \) bezeichnet.
\end{enumerate}
\subsubsection*{Korollar}
\begin{enumerate}[(i)]
	\item \(\mathring{A} \subset A\)
	\item \(\mathring{A} \subset \overline{A}\)
	\item \(\partial A \subset \overline{A}\)
	\item \(\overline{A} = \mathring{A} \cup \partial A \)
	\item \(\overline{A} = A \cup \partial A \) (schwächere Aussage als (iv))
\end{enumerate}

\subsection{Definition von offen und abgeschlossen}
Eine Menge \(A \subset \Rn\) heißt
\begin{enumerate}[(i)]
	\item \textbf{offen}, wenn \(A = \mathring{A} \) gilt (\(A\) besteht nur aus inneren Punkten)
	\item \textbf{abgeschlossen}, wenn \(\partial A \subset A \) gilt (wenn der Rand in der Menge enthalten ist)
\end{enumerate}

\subsection{Beispiele}
\begin{enumerate}[1.~]
	\item Jede \(\varepsilon\)-Umgebung \(U_\varepsilon(x_0 \in \Rn)\) ist offen
	\item Sei \(I \subset \R\), dann gilt
	\begin{enumerate}[(i)]
		\item \(I\) ist offen, wenn \(I = (a,b)\) mit \( -\infty \leqslant a \leqslant b \leqslant \infty \) \\
		für \(a = b\) gilt \(I = \varnothing\) mit \(I\) offen \\
		und für \(a = -\infty, b = \infty\) ist \(I\) auch offen
		\item \(I\) ist abgeschlossen, wenn \(I = [a,b]\) mit \(a,b \in \R\) \\
		oder \(I = (-\infty, b]\) oder \(I = [a, \infty) \) oder \(I = (-\infty, \infty) = \R\)
	\end{enumerate}
	(die reellen Zahlen sind offen und abgeschlossen zugleich)
\end{enumerate}

\subsection{Satz}
für \(A \subset \Rn\) sind folgenden Aussagen äquivalent:
\begin{enumerate}[(i)]
	\item \(A\) ist abgeschlossen \(A = \overline{A}\)
	\item \(A\) enthält alle Häufungspunkte, \(A' \subset A\)
	\item \(A\) enthält alle Randpunkte, \(\partial A \subset A\)
	\item \(A^c\) ist offen
\end{enumerate}

\subsection{Satz}
\begin{enumerate}[(i)]
	\item \(\varnothing\) und \(\Rn\) sind offen.
	\item Die Vereinigung beliebig vieler offene Mengen ist offen:
	\begin{align*}
		\bigcup_{j \in J} \left( O_j \textrm{ offen} \right) = O \textrm{ offen}
	\end{align*}
	\item Der Durchschnitt \underline{endlich} vieler offener Mengen ist offen:
	\begin{align*}
		\bigcap_{j = 1}^{n} \left( O_j \textrm{ offen} \right) = O \textrm{ offen}
	\end{align*}
	\textit{Bemerkung}: Für unendlich viele offene Mengen gilt dies nicht immer:
	\begin{align*}
		\bigcap_{k = 1}^{\infty} \left( -\frac{1}{k}, \frac{1}{k} \right) = \left( -1, 1 \right) \cap \left( -\frac{1}{2}, \frac{1}{2} \right) \cap \left( -\frac{1}{3}, \frac{1}{3} \right) \cap ... = \left\{ 0 \right\} \textrm{ abgeschlossen}
	\end{align*}
\end{enumerate}

\subsubsection{Beispiel}
Seien \(A_1, A_2\) zwei abgeschlossene Mengen, dann gilt
\begin{enumerate}[(i)]
	\item \(A_1 \cup A_2\) ist abgeschlossen \\
	\Beweis[Beweisidee] \(A_1\) ist abgeschlossen \(\Rightarrow A_1^c\) ist offen \\
	\begin{align*}
		\left( A_1 \cup A_2 \right)^c \stackrel{\textrm{De Morgan}}{=}& \underbrace{A_1^c}_{\textrm{offen}} \cap \underbrace{A_2^c}_{\textrm{offen}} \textrm{ ist offen wegen Satz 1.1.8} \\
		\left( \left( A_1 \cup A_2 \right)^c \right)^c =& ~A_1 \cup A_2 \textrm{ ist abgeschlossen}
	\end{align*}
	\OED
\end{enumerate}

\subsection{Satz}
\begin{enumerate}[(i)]
	\item \(\varnothing\) und \(\Rn\) sind abgeschlossen.
	\item Der Durchschnitt beliebig vieler abgeschlossener Mengen ist abgeschlossen:
	\begin{align*}
		\bigcap_{j \in J} \left( A_j \textrm{ abgeschlossen} \right) = A \textrm{ abgeschlossen}
	\end{align*}
	\item Die Vereinigung \underline{endlich} vieler abgeschlossenen Mengen ist abgeschlossen:
	\begin{align*}
		\bigcup_{j = 1}^{n} \left( A_j \textrm{ abgeschlossen} \right) = A \textrm{ abgeschlossen}
	\end{align*}
	\textit{Bemerkung}: Für unendlich viele abgeschlossene Mengen gilt dies nicht immer:
	\begin{align*}
		\bigcup_{k = 1}^{\infty} \left[ -1 + \frac{1}{n}, 1 - \frac{1}{n} \right] = \left\{ 0 \right\} \cup \left[ -\frac{1}{2}, \frac{1}{2} \right] \cup \left[ -\frac{2}{3}, \frac{2}{3} \right] \cup ... = \left( -1, 1 \right) \textrm{ offen}
	\end{align*}	 
\end{enumerate}

\subsection{Definition von beschränkt und kompakt}
Eine Menge \(A \subset \Rn\) heißt:
\begin{enumerate}[(i)]
	\item \textbf{beschränkt} wenn \(\exists~ c > 0 \) mit \( \Vert x \Vert < c \quad \forall~ x \in A\)
	\item \textbf{kompakt}, wenn \(A\) abgeschlossen und beschränkt ist.
\end{enumerate}

\section{Folgen}

\subsection{Definition von Konvergenz und Beschränktheit}

Eine Folge \((a_k)_{k=1}^\infty \) heißt
\begin{enumerate}[(i)]
	\item \textbf{konvergent}, wenn gilt
	\begin{align*}
		\exists~ a \in \Rn \quad \textrm{mit} \quad \forall~ \varepsilon > 0 \quad \exists~ N(\varepsilon) : \quad \Vert a_k - a \Vert \quad \forall~ k \geqslant N(\varepsilon)
	\end{align*}
	Dann ist \(a\) der Grenzwert der Folge:
	\begin{align*}
		a = \lim_{k \rightarrow \infty} a_k \quad \textrm{oder} \quad a_k \stackrel{k \rightarrow \infty}{\rightarrow} a
	\end{align*}
	\item \textbf{beschränkt}, wenn \(\exists~ c > 0 \) mit \(\Vert a_k \Vert < c \quad \forall~ k \)
\end{enumerate}

\subsection{Bemerkung}

Wenn eine Folge \((a_k) = \left( \begin{array}{c} \left( a_1^{(k)} \right) \\ \vdots \\ \left( a_n^{(k)} \right)	\end{array} \right) \in \Rn\) konvergiert, so gilt
\begin{enumerate}[(i)]
	\item  \(\Leftrightarrow\) jede Komponente \( \left( a_1^{(k)}\right), ..., \left( a_n^{(k)} \right) \) konvergiert:
	\begin{align*}
		\lim_{k \rightarrow \infty} a_k = a \quad \Leftrightarrow \quad \lim_{k \rightarrow \infty} a_i^{(k)} = a_i \quad \textrm{für } i = 1, ..., n
	\end{align*}
	\item \(\Leftrightarrow (a_k) \) erfüllt das \textbf{Cauchy-Kriterium}:
	\begin{align*}
		\forall~ \varepsilon > 0 \quad \exists~ N(\varepsilon) : \quad \Vert a_k - a_l \Vert < \varepsilon \quad \forall~ k,l \geqslant N(\varepsilon)
	\end{align*}
	\item \(\Leftrightarrow\) jede Teilfolge von \((a_k)\) konvergiert gegen \(a\): \( a_{l_k} \stackrel{k \rightarrow \infty}{\rightarrow} a \) für \( l_1 \geqslant 1, l_2 \geqslant 2, ...\)
	\item der Grenzwert \(a\) ist eindeutig.
\end{enumerate}

\subsection{Satz von Bolzano Weierstraß}
Jede beschränkte Folge im \(\Rn\) besitzt einen konvergente Teilfolge.

\subsubsection*{Beispiele}
\begin{enumerate}[(i)]
	\item \(n = 1\): Sei \( A \leqslant (a_k) \leqslant B \quad \forall~ k \). Konstruiert man eine neue Schranke mit \(\frac{A + B}{2} \) so liegen wiederum \(\infty\) viele Elemente in der oberen und/oder unteren Hälfte.
	\item Sei \((a_k) = \left( \begin{array}{c} (x_k) \\ (y_k) \end{array} \right) \) eine beschränkte Folge im \(\R^2\) \\
\(\Rightarrow\) \((x_k), (y_k)\) sind beschränkte Folgen \\
\(\stackrel{\substack{\textrm{Satz von}\\\textrm{Bolzano}\\\textrm{Wierstraß}}}{\Rightarrow} \exists~ (x_k), (y_k)\) sind konvergent
\end{enumerate}

\subsection{Abschließende Bemerkungen}
\begin{enumerate}[(i)]
	\item Grenzwert Rechenregeln können aus dem \(\R\) für \(\Rn\) übernommen werden. \\
	\textit{z.b.} \( a_k \stackrel{k \rightarrow \infty}{\rightarrow} a, \quad b_k \stackrel{k \rightarrow \infty}{\rightarrow} b 
	\quad \Rightarrow \quad a_k^\top b_k \stackrel{k \rightarrow \infty}{\rightarrow} a^\top b \)
	\item Es gibt viele Zusammenhänge zwischen den Eigenschaften von Folgen und den topologischen Eigenschaften von Mengen. \\
	\textit{z.b.} Sei \(A \subset \Rn\) und \(a \in \Rn\) ein Häufungspunkt \\
	\(\Leftrightarrow \quad \exists (a_k)_{k=1}^\infty \) mit \( a_k \in A \setminus \left\{ a \right\} \forall~ k \quad \) und \( \quad a_k \stackrel{k \rightarrow \infty}{\rightarrow} a\)
\end{enumerate}

\section{Funktionsgrenzwerte und Stetigkeit}

\subsection{Definition}
Eine Funktion \(f : A \subset \Rn \rightarrow \Rm \) nennt man eine Funktion mit \(n\)-Veränderlichen.
\begin{align*}
	f(x_1, ..., x_n) = f( \left( \begin{array}{c} x_1 \\ \vdots \\ x_n \end{array} \right) ) = \left( \begin{array}{c}
		f_1(x_1, ..., x_n) \\
		\vdots \\
		f_m(x_1, ..., x_n) \\
	\end{array} \right) \quad \textrm{mit} \quad f_1, ..., f_m : \Rn \rightarrow \R
\end{align*}

\subsection{Definition Grenzwert/Limes}
Sei \(f : A \subset \Rn \rightarrow \Rm \) und \(a \in \overline{A}\). Ein \(b \in \Rm\) heißt Grenzwert von \(f\) für \(x \rightarrow a\), wenn gilt:
\begin{align*}
	\forall \varepsilon > 0 \quad \exists~ \delta(\varepsilon) > 0 : \quad \Vert f(x) - b \Vert < \varepsilon \quad \forall~ x \in \dot{U}_{\delta(\varepsilon)}(a) \cap A
\end{align*}
\textit{Bemerkung}: Die Funktion \(f\) muss in \(a\) nicht stetig sein, so kann z.b. gelten: \\
\( \lim_{x \rightarrow a} f(x) = b \neq f(a) \)

\subsection{Korollar}
Sei \(f : A \subset \Rn \rightarrow \Rm, a \in \overline{A}, b \in \Rm\) dann sind folgende Aussagen äquivalent:
\begin{enumerate}[(i)]
	\item \( f(x) \stackrel{x \rightarrow a}{\rightarrow} b \)
	\item \( \Vert f(x) - b \Vert \stackrel{x \rightarrow a}{\rightarrow} 0 \in \R^1 \) (Eine Norm bildet immer auf ein Skalar ab)
	\item \( f_1(x) \stackrel{x \rightarrow a}{\rightarrow} b_1, ..., f_m(x) \stackrel{x \rightarrow a}{\rightarrow} b_m \)
\end{enumerate}
Zusätzlich gilt das \textbf{Cauchy-Kriterium}:
\begin{align*}
	\lim_{x \rightarrow a} f(x) = b \quad \Leftrightarrow \quad \forall~ \varepsilon > 0 ~ \exists~ \delta(\varepsilon) > 0: \quad 
	\Vert f(x), f(y) \Vert < \varepsilon \quad \forall~ x,y \in \dot{U}_{\delta(\varepsilon)}(a) \cap A
\end{align*}

\subsection{Beispiel}
Sei \( f(x,y) = \frac{xy}{x^2 + y^2} \)
\begin{align*}
	a_k &= \left( \begin{array}{c} x_k \\ y_k \end{array} \right) = \left( \begin{array}{c} \frac{1}{k} \\ \frac{1}{k} \end{array} \right), \quad 
	f(a_k) = \frac{\frac{1}{k^2}}{\frac{1}{k^2} + \frac{1}{k^2}} = \frac{1}{2} \quad \forall~ k \\
	b_k &= \left( \begin{array}{c} x_k \\ 0 \end{array} \right) \mitt x_k \stackrel{k \rightarrow \infty}{\rightarrow} 0, \quad
	f(b_k) = \frac{0}{x_k^2} \quad \forall~ k \\
	&\textrm{Da } \lim_{k \rightarrow \infty} f(a_k) = \frac{1}{2} \neq 0 = \lim_{k \rightarrow \infty} f(b_k) \textrm{ kann der Grenzwert nicht existieren.}
\end{align*}

\subsection{Lemma Folgenkriterium}
Sei \(f : A \subset \Rn \rightarrow \Rm, a \in \overline{A} \)
\begin{align*}
	\underbrace{\exists b \in \Rm \mitt \lim_{x \rightarrow a} f(x) = b}_{\textrm{der Grenzwert } b \textrm{ existiert}} \quad &\Leftrightarrow \quad
	\underbrace{
		\begin{array}{l}
			\textrm{jede Folge } (x_k)_{k=1}^\infty \subset A \mitt x_k \neq a ~ \forall~ k \textrm{ und } x_k \stackrel{k \rightarrow \infty}{\rightarrow} a \\
			\Rightarrow  \quad f(x_k) \stackrel{k \rightarrow \infty}{\rightarrow} b
		\end{array}
	}_{\textrm{jede beliebige Folge konvergiert gegen } b}
\end{align*}

\subsection{Satz zu Grenzwerte verketteter Funktionen}
Sei \(A \subset \Rn, B \subset \Rm, a \in \overline{A}, f: A \rightarrow B, g: \overline{B} \rightarrow \R^l \)
\begin{align*}
	\exists~ b \in \overline{B} \mitt \lim_{x \rightarrow a} f(x) = b, \quad
	\exists~ c \in \R^l \mitt \lim_{y \rightarrow b} g(y) = c \quad \Rightarrow \quad
	\lim_{x \rightarrow a} \underbrace{g\left(f(x)\right)}_{(g \circ f)(x)} = \lim_{y \rightarrow b} g(y) = c
\end{align*}

\subsection{Beispiel}
Sei \(f(x,y) = e^{-x^2 + y^2} = \exp\left( g(x,y) \right) \mitt g(x,y) = x^2 + y^2\), dabei gilt:
\begin{align*}
	\lim_{(x,y)^\top \rightarrow (0,0)^\top} g(x,y) = \lim_{(x,y)^\top \rightarrow (0,0)^\top} x^2 + y^2 = 0
	\quad \Rightarrow \quad \lim_{z \rightarrow 0} f(z) = \lim_{z \rightarrow 0} e^z = 1 \\
\end{align*}

\subsection{Definition der Stetigkeit}
Sei \(f: A \subset \Rn \rightarrow \Rm\)
\begin{enumerate}[(i)]
	\item \(f\) ist \textbf{stetig} in \(a \in A\) wenn gilt:
	\begin{align*}
		\forall~ \varepsilon > 0 ~ \exists \delta(\varepsilon) : \quad \Vert f(x) - f(a) \Vert < \varepsilon \quad \forall~ x \in U_{\delta(\varepsilon)}(a) \cap A
	\end{align*}
	\textit{Bemerkung}: Es wird \( \lim_{x \rightarrow a} f(x) = f(a) \) gefordert. \\
	Diese Definition unterscheidet sich in der nicht punktierten \(\varepsilon\)-Umgebung und es gilt \(f(a)\) anstatt b.
	\item \(f\) ist stetig auf \(A\), wenn \(f\) in jedem Punkt \(a \in A\) stetig ist.
\end{enumerate}

\subsection{Bemerkung}
\begin{enumerate}[(i)]
	\item Kompositionen stetiger Funktionen sind wieder stetig: \(f, g\) stetig \(\Rightarrow f+g, f-g, ...\) stetig
	\item Das Folgenkriterium überträgt sich: \\
	Sei \((a_k)_{k=1}^\infty \) eine Folge in \(A\) mit \(\lim_{k \rightarrow \infty} a_k = a  \quad \Leftrightarrow \quad \lim_{k \rightarrow \infty} f(a_k) = f(a)\)
	\item Ist \(A\) kompakt, dann nimmt eine stetige Funktion \(f : A \rightarrow \R\) immer ein Maximum und Minimum an:
	\begin{align*}
		\exists~ x_m, x_M \in A \mitt f(x_m) = \min_{x \in A} f(x), f(x_M) = \max_{x \in A} f(x)
	\end{align*}
\end{enumerate}

\section{Partielle Ableitungen, Richtungsableitungen}
\subsection{Definition der partiellen Ableitung}
Die Funktion \(f : A \subset \Rn \rightarrow \Rm\) heißt \textbf{partielle differenzierbar} in \(a \in A\) nach der \(k\)-ten Variable \(x_k \mitt k \in \left\{ 1, ..., n\right\} \) wenn der folgender Grenzwert existiert:
\begin{align*}
	\frac{\partial}{\partial x_k} f(a) = f_{x_k}(a) = \lim_{h \rightarrow 0} \frac{f(a + h \cdot e_k) - f(a)}{h}
\end{align*}
Existieren alle partielle Ableitungen \(f_{x_1}(a), ..., f_{x_n}(a)\), dann ist der \textbf{Gradient} von \(f\) wie folgt definiert:
\begin{align*}
	\nabla f(a) = \left( \begin{array}{c}
		f_{x_1} (a) \\
		\vdots \\
		f_{x_n} (a)
	\end{array} \right)
\end{align*}
und die Funktion \(f\) heißt mindestens einmal partielle differenzierbar. Sind die partiellen Ableitungen \(f_{x_1}(a), ..., f_{x_n}(a)\) zudem stetig, so heißt \(f\) einmal stetig differenzierbar: \( f \in C^1(A,\Rm)\) oder kurz \( f \in C^1(A) \).

\subsection{Beispiel}
Sei \(f(x,y,z) = x^2 - xy + 3z\)
\begin{align*}
	\frac{\partial}{\partial x} f(x,y,z) &= 
	\lim_{h \rightarrow 0} \frac{f(x+h,y,z) - f(x,y,z)}{h} \\
	&= \lim_{h \rightarrow 0} \frac{(x+h)^2 - (x+h)y + 3z - ( x^2 - xy + 3z)}{h} \\
	&= \lim_{h \rightarrow 0} \frac{(x+h)^2 - x^2}{h} - \frac{(x+h)y-xy}{h} + \frac{3z - 3z}{h} \\
	&= \left( \frac{d}{dx} x^2 \right) - \left( \frac{d}{dx} x \right)y + \left( \frac{d}{dx} 0 \right) z \\
	&= 2x - y + 0 \\
	&\Rightarrow \nabla f(x,y,z) = \left( \begin{array}{c}
		2x - y \\
		-x \\
		3	
	\end{array} \right)
\end{align*}

\subsection{Definition der Richtungsableitung}
Sei \(a, r \in \Rn\) mit \(\Vert r \Vert = 1\) (normiert), \(f: \Rn \rightarrow \Rm\), dann heißt der folgende Grenzwert die Richtungsableitung von \(f\) bei \(a\) in Richtung \(r\):
\begin{align*}
	\frac{\partial}{\partial r} f(a) = f_r (a) = \lim_{h \rightarrow 0} \frac{f(a + h \cdot r) - f(a)}{h}
\end{align*}

\subsubsection*{Bemerkung}
\begin{enumerate}[(i)]
	\item Ist \(r = e_k\), dann erhalten wir gerade eine partielle Ableitung.
	\item Es gibt Funktionen die in \(a\) in \underline{jede Richtung differenzierbar} sind, aber in \(a\) \underline{nicht stetig} sind!
\end{enumerate}

\section{Total Differenzierbarkeit}
\textit{Idee}: Differenzierbare Funktionen sind lokal im Punkt \(x_0\) linear approximierbar:
\begin{align*}
	f(x) = f(x_0) + f'(x_0)(x-x_0) + \underbrace{r(x)\Vert x-x_0 \Vert}_{\tilde{r}(x)}
\end{align*}
Dabei muss der Fehler \(\tilde{r}(x) = r(x)\Vert x - x_0 \Vert \) \textit{schneller gegen Null gehen als \(x\) gegen \(x_0\)} also muss \(\tilde{r}(x) = \hbox{o}(x - x_0)\) gelten (Landau-Notation: klein-oh).

\subsection{Definition der totalen Differenzierbarkeit}
Sei \(f : A \subset \Rn \rightarrow \Rm, A\) offen, \(x_0 \in A\)
\begin{enumerate}[(i)]
	\item Die Funktion \(f\) nennt man \textbf{total differenzierbar} bei \(x_0\), wenn eine Matrix \(A \in \Rmxn\) existiert, mit der sich die Funktion \(f\) in einer \(\varepsilon\)-Umgebung um \(x_0\) mittels einer Hyperebene approximieren lässt:
	\begin{align*}
		f(x) = f(x_0) + A(x-x_0) + r(x)\Vert x - x_0 \Vert
	\end{align*}
	Dann nennt man die Matrix \(A = f'(x_0) = \frac{\partial}{\partial x} f(x_0)\) die total Ableitung von \(f\) in \(x_0\).
	\item Ist \(f = \left( \begin{array}{c} f_1 \\ \vdots \\ f_m \end{array} \right) \) partiell diff'bar, so nennt man die Ableitung \textbf{Jacobi-Matrix}:
	\begin{align*}
		f'(x_0) = \frac{\partial}{\partial x} f(x_0) = J_f(x_0) = \left( \begin{array}{ccc}
			\frac{\partial}{\partial x_1} f_1(x_0) & \hdots & \frac{\partial}{\partial x_n} f_1(x_0) \\
			\vdots & & \vdots \\
			\frac{\partial}{\partial x_1} f_m(x_0) & \hdots & \frac{\partial}{\partial x_n} f_m(x_0) \\
		\end{array} \right) \in \Rmxn
	\end{align*}
	\textit{Bemerkung}: Es gilt: \( \exists f'(x_0) \quad \Rightarrow \quad f'(x_0) = J_f(x_0) \), \underline{nicht} aber die Gegenrichtung! Es kann also sein, dass die Jacobi-Matrix \(J_f\) existiert die Funktion aber \underline{nicht total diff'bar} ist.
\end{enumerate}

\subsection{Beispiele}
\begin{enumerate}[(i)]
	\item \begin{align*}
		f(r,\varphi) = r \cdot \left( \begin{array}{c} \cos \varphi \\ \sin \varphi \end{array} \right) \quad \Rightarrow \quad J_f = \left( \begin{array}{cc}
			\cos \varphi & -r \sin \varphi \\
			\sin \varphi & r \cos \varphi
		\end{array} \right)
	\end{align*}
	\item \(f(x) = a + b^\top(x - x_0), \quad f : \Rn \rightarrow \R, \quad a \in \R, \quad b,x_0 \in \Rn\) \\
	\(\Rightarrow \quad f(x_0) = a, \quad f'(x_0) = b^\top \)
	\item \(f(x) = a + A(x - x_0), \quad f : \Rn \rightarrow \Rm, \quad a \in \Rm, \quad A \in \Rmxn, \quad x_0 \in \Rn\) \\
	\(\Rightarrow \quad f(x_0) = a, \quad f'(x_0) = A \)
\end{enumerate}
\textit{Bemerkung}: Beispiel (ii) und (iii) sind lineare Funktionen.

\subsection{Satz}
Ist \(f : A \subset \Rn \rightarrow \Rm\) in jedem Punkt \(x_0 \in A\) total differenzierbar, so ist \(f\) stetig in \(A\). \\

\Beweis
\begin{align*}
	f(x) &= \underbrace{f(x_0)}_{\stackrel{x \rightarrow x_0}{\rightarrow} f(x_0)} + 
	\underbrace{A \underbrace{(x-x_0)}_{\stackrel{x \rightarrow x_0}{\rightarrow} 0 \in \Rn}}_{\stackrel{x \rightarrow x_0}{\rightarrow} 0 \in \Rn} + 
	\underbrace{r(x)}_{\stackrel{x \rightarrow x_0}{\rightarrow} 0 \in \Rm} 
	\underbrace{\Vert x - x_0 \Vert}_{\stackrel{x \rightarrow x_0}{\rightarrow} 0 \in \R}
	\qquad \mitt r(x) \stackrel{x \rightarrow x_0}{\rightarrow} 0 \\
	\lim_{x \rightarrow a} f(x) &= f(x_0) \quad _\square\\
\end{align*}
\OED

\subsection{Satz}
Sei \(f : A \subset \Rn \rightarrow \Rm, x_0 \in A\)
\begin{enumerate}[a.~]
	\item Ist \(f\) total differenzierbar in \(x_0\), so gilt
	\begin{enumerate}[(i)]
		\item \(f'(x_0) = J_f(x_0) \)
		\item \(f\) ist in jede Richtung \(r\) differenzierbar mit: \( \frac{\partial}{\partial r} f(x_0) = J_f(x_0) \cdot r \)
	\end{enumerate}
	\Beweis
	Es ist zu zeigen, dass
	wenn \(f\) differenzierbar in \(x_0\) die Ableitung gerade die Form \(\frac{\partial}{\partial r} f(x_0) = J_f(x_0) \cdot r \) besitzt. Für diese Ableitung muss folgendes gelten:
	\begin{align*}
		&f(x) = f(x_0) + A(x-x_0) + \tilde{r}(x) \mitt A = f'(x_0)
		\textrm{ und } \tilde{r} \in \hbox{o}(\Vert x - x_0 \Vert) \Rightarrow \frac{\tilde{r}(x)}{\Vert x - x_0 \Vert} \stackrel{x \rightarrow x_0}{\rightarrow} 0 \\
		&\stackrel{f(x) = f(x_0 + r \cdot h}{\Leftrightarrow} \quad
		f(x_0 + r \cdot h) - f(x_0) = A \cdot r \cdot h + \tilde{r}(x) = f'(x_0) r h + \tilde{r}(x)
	\end{align*}		
	also muss folgendes gezeigt werden:
	\begin{align*}
		&\left\Vert 
		\underbrace{\frac{f(x_0 + r \cdot h) - f(x_0)}{h}}_{\textrm{Diff'Quotient für }\frac{\partial f}{\partial r}} - 
		\underbrace{f'(x_0)\cdot r}_{\substack{\textrm{Grenzwert-}\\\textrm{kandidat}}} \right\Vert \stackrel{h \rightarrow 0}{\rightarrow} 0 \\
		&\left\Vert \frac{f(x_0 + r \cdot h) - f(x_0)}{h} - f'(x_0) \cdot r \right\Vert =
		\left\Vert
		\frac{f'(x_0) r h + \tilde{r}(x)}{h} - f'(x_0)r
		\right\Vert = \\
		&\left\Vert
		\frac{f'(x_0)r \not{h}}{\not{h}}
		+ \frac{\tilde{r}(x)}{h} - 
		f'(x_0)r
		\right\Vert = 
		\left\Vert \frac{\tilde{r}(x)}{h} \right\Vert =
		\left\Vert \frac{\tilde{r}(x)}{x - x_0} \right\Vert
		\stackrel{x \rightarrow x_0}{\rightarrow} 0
	\end{align*}
	Ist \(r = e_k\) so erhält man gerade eine Spalte der Jacobi-Matrix.
	\OED
	
	\item Existieren in \(x_0\) alle partiellen Ableitungen (also \underline{alle Komponenten der Jacobi-Matrix}) und diese \underline{stetig} sind \(\quad \Rightarrow \quad f\) ist in \(x_0\) total differenzierbar. \\
	
	\Beweis
	Für den Fall \(n=2, m=1\) muss folgendes gezeigt werden:
	\begin{align*}
		&\exists~ \nabla f(x_0) \textrm{ und } \tilde{r}(x) \mitt 
		f(x) = f(x_0) + \nabla f(x_0)^\top (x-x_0) + \tilde{r}(x) \\
		&\textrm{oder } 
		\left\Vert
			\frac{f(x) - f(x_0)}{x - x_0} - \nabla f(x_0)
		\right\Vert =
		\frac{\left\Vert f(x) - f(x_0) - \nabla f(x_0)(x-x_0)\right\Vert}{\left\Vert x - x_0 \right\Vert}
		\stackrel{x \rightarrow x_0}{\rightarrow} 0 \\
	\end{align*}
	Sei \(x = \left(\begin{array}{c} x_1 \\ x_2 \end{array} \right)\) und sei \(x_0 = a = \left(\begin{array}{c} a_1 \\ a_2 \end{array} \right)\). \\
	Nebenrechnung: Definition zweier Hilfsfunktionen \(g_1, g_2\):
	\begin{align*}
		&\textrm{Sei } g_1(t) = f(t,x_2) \quad g_2:\R \rightarrow \R \\
		\stackrel{\textrm{MWS}}{\Rightarrow}\quad& \exists~ \xi_1 \in (a_1, x_1) \mitt g_1'(\xi_1) = \frac{g_1(x_1) - g_1(a_1)}{x_1 - a_1} \\
		&= \frac{\partial}{\partial x_1} f(\xi_1, x_2) = \frac{f(x_1, x_2) - f(a_1, x_2)}{x_1 - a_1} \\
		\Leftrightarrow\quad& f(x_1,x_2) - f(a_1,x_2) = \frac{\partial}{\partial x_1} f(\xi_1,x_2) (x_1 - a_1) \\
		\textrm{analog gilt für}\quad& g_2(t) = f(a_1, t) \quad g_2 : \R \rightarrow \R \\
		& f(a_1, a_2) - f(a_1, x_2) = \frac{\partial}{\partial x_2} f(a_1, \xi_2) (x_2 - a_2)
	\end{align*}	
	Damit gilt:
	\begin{align*}
		f(x) - f(a) &= f(x_1,x_2) - f(a_1,a_2) = 
		f(x_1, x_2) \underbrace{- f(a_1, x_2) + f(a_1, x_2)}_{=0} - f(a_1, a_2) \\
		&\stackrel{\substack{\textrm{mit Resultat}\\
		\textrm{aus Neben-}\\
		\textrm{rechnung}}}{=} \frac{\partial}{\partial x_1} f(\xi_1, x_2)(x_1 - a_1) + 
		\frac{\partial}{\partial x_2} f(a_1, \xi_2)(x_2 - a_2) \\
		&\qquad= \left(\begin{array}{c}
			f_{x_1}(\xi_1, x_2) \\
			f_{x_2}(a_1, \xi_2)
		\end{array} \right)^\top \left( \begin{array}{c}
			x_1 - a_1 \\
			x_2 - a_2
		\end{array} \right) = \left(\begin{array}{c}
			f_{x_1}(\xi_1, x_2) \\
			f_{x_2}(a_1, \xi_2)
		\end{array} \right)^\top (x - a) \\
	\end{align*}
	Für \(x \rightarrow a\) gilt:
	\begin{align*}
		x_1 \rightarrow a_1 \quad x_2 \rightarrow a_2 \\
		\xi_1 \rightarrow a_1 \quad \xi_2 \rightarrow a_2
	\end{align*}
	da \(f_{x_1}, f_{x_2}\) \underline{stetig}, folgt:
	\begin{align*}
		f_{x_1} (\xi_1, x_2) &\rightarrow f_{x_1} (a_1, a_2) \\
		f_{x_2} (a_1, \xi_2) &\rightarrow f_{x_2} (a_1, a_2) \\
		\Rightarrow \left(\begin{array}{c}
			f_{x_1}(\xi_1, x_2) \\
			f_{x_2}(a_1, \xi_2)
		\end{array} \right)^\top &\rightarrow \nabla f (a_1, a_2) = \nabla f(x_0)
	\end{align*}
	und es gilt:
	\begin{align*}
		\frac{\left\Vert f(x) - f(x_0) - 
		\overbrace{\left(\begin{array}{c}
			f_{x_1}(\xi_1, x_2) \\
			f_{x_2}(a_1, \xi_2)
		\end{array} \right)^\top}^{\stackrel{x \rightarrow x_0}{\rightarrow} \nabla f(x_0)}
		(x-x_0)\right\Vert}{\left\Vert x - x_0 \right\Vert}
		\stackrel{x \rightarrow x_0}{\rightarrow} 0
	\end{align*}
	\OED
	
\end{enumerate}


\subsection{Bemerkung}
Sei \(r\) eine Richtung mit \(\Vert r \Vert = 1\) und \(x = x_0 + r\), dann gilt:
\begin{align*}
	f(x) &\approx f(x_0) + \nabla f(x_0)^\top \cdot r \\
	&\Rightarrow \textrm{1. Fall}: \quad r, \nabla f(x_0) \textrm{ zeigen in dieselbe Richtung}: \\
	&\qquad f(x) - f(x_0) \approx \Vert \nabla f(x_0) \Vert \Vert r \Vert = \Vert \nabla f(x_0) \Vert > 0 \\
	&\Rightarrow \textrm{2. Fall}: \quad r, \nabla f(x_0) \textrm{ zeigen in entgegengesetzte Richtungen}: \\
	&\qquad f(x) - f(x_0) \approx - \Vert \nabla f(x_0) \Vert < 0
\end{align*}
In allen Fällen gilt Näherungsweise:
\begin{align*}
	- \Vert \nabla f(x_0) \Vert  < \nabla f(x_0)^\top r \leqslant \Vert \nabla f(x_0) \Vert
\end{align*}
\textit{Fazit}: Beim Reinzoomen sind die Höhenlinien parallel. Der Gradient zeigt in Richtung des steilsten Anstieges.

\subsection{Satz zur Kettenregel}
Ist \(f: A \subset \Rn \rightarrow B \subset \Rm\) differenzierbar in \(a \in A\) und \(g: B \subset \Rm \rightarrow \R^l\) differenzierbar in \(b \in B\), so gilt:
\begin{align*}
	(g \circ f)'(a) = g'\left(\underbrace{f(a)}_{=b}\right) f'(a) = 
	\underbrace{ J_g (b) }_{\in \R^{l \times m}}
	\underbrace{ J_f (a) }_{\in \R^{m \times n}}
\end{align*}

\Beispiel[Beispiel aus der Strömungsmechanik]
Die Funktion \(f: \R^4 \rightarrow \R, f = f(x,y,z,t) \) beschreibe die Eigenschaften eines Teilchens in einer Strömung. Dabei kann die Bewegung der Position im Raum \(x,y,z\) als Abhängigkeit von der Zeit beschrieben werden. Dazu definieren wir den Weg \(\gamma(t)\):
\begin{align*}
	\gamma: \R \rightarrow \R^4, \quad
	\gamma(t) = \left( \begin{array}{c}
		x(t) \\
		y(t) \\
		z(t) \\
		t
	\end{array} \right) \quad\mitt\quad
	\frac{d \gamma}{dt} = \left( \begin{array}{c}
		\frac{d x}{dt} \\
		\frac{d y}{dt} \\
		\frac{d z}{dt} \\
		1
	\end{array} \right)
\end{align*}
Nun leiten wir die verkettete Funktion \(\hat{f}(t) = (f \circ \gamma)(t) = f(\gamma(t))\) nach der Zeit \(t\) ab:
\begin{align*}
	\frac{d\hat{f}}{dt} &= \left( \hat{f}(\gamma(t)) \right)' = f'(h(t)) \gamma'(t) = \nabla f \cdot \frac{d\gamma}{dt} \\
	&= \left( \begin{array}{c}
		\frac{\partial f}{\partial x} \\
		\frac{\partial f}{\partial y} \\
		\frac{\partial f}{\partial z}
	\end{array} \right)^\top 
	\left( \begin{array}{c}
		\frac{d x}{dt} \\
		\frac{d y}{dt} \\
		\frac{d z}{dt} \\
		1
	\end{array} \right) \\
	&= \frac{\partial f}{\partial x} \underbrace{\frac{dx}{dt}}_{u}
	+ \frac{\partial f}{\partial y} \underbrace{\frac{dy}{dt}}_{v}
	+ \frac{\partial f}{\partial z} \underbrace{\frac{dz}{dt}}_{w}
	+ \frac{\partial f}{\partial t}
\end{align*}
Dabei beschreibt der Vektor \(\left(\begin{array}{c} u \\ v \\ w \end{array}\right) \) die Geschwindigkeit im Raum.
\Beispielende

\section{Lokale Extremstellen und Mittelwertsätze}

In einer Dimension gilt:
\subsubsection*{1. Mittelwertsatz}
Ist \(f\) differenzierbar auf \((a,b)\) und stetig auf \([a,b]\), so gilt:
\begin{align*}
	\exists~ \xi \in (a,b) \mitt f'(\xi) = \frac{f(b) - f(a)}{b - a}
\end{align*}

\subsubsection*{Satz von Rolle}
Ist \(f\) differenzierbar auf \((a,b)\) und stetig auf \([a,b]\) und gilt \(f(a) = f(b)\), so gilt:
\begin{align*}
	\exists~ \xi \in (a,b) \mitt f'(\xi) = 0
\end{align*}

\subsection{Definition lokale/globale Extremstellen}
\begin{enumerate}[(i)]
	\item Eine Funktion \(f: A \subset \Rn \rightarrow \R \) (Skalarfeld) hat bei \(x_0 \in A\) ein lokales Minimum (Maximum) wenn in einer Umgebung \(U = U_\varepsilon (x_0) \cap A\) für \( \varepsilon > 0\) (offen bezüglich \(A\)) von \(x_0\) gilt:
	\begin{align*}
		f(x_0) \stackrel{(\geqslant)}{\leqslant} f(x) \quad \forall x \in U
	\end{align*}	 
	Ist bei \(x_0\) ein lokales Minimum (Maximum) dann nennt man \(x_0\) eine lokale Extremstelle. 
	\item \(f\) besitzt in \(x_0\) ein globales Minimum (Maximum), wenn gilt:
	\begin{align*}
		f(x_0) \stackrel{(\geqslant)}{\leqslant} f(x) \quad \forall x \in A
	\end{align*}
\end{enumerate}

\subsection{Satz zur notwendigen Bedingung für eine lokale Extremstelle}
Besitzt \(f: \mathring{A} \subset \Rn \rightarrow \R \) bei \(x_0 \in A\) eine lokale Extremstelle und \(f\) ist partiell differenzierbar, dann ist
\begin{align*}
	\nabla f(x_0) = 0
\end{align*}
\textit{Bemerkung}: Der Rand ist ausgeschlossen da \(\mathring{A}\) (alle inneren Punkte) in der Definition verwendet wurde.\\
Auch gilt:
\begin{align*}
	x_0 \textrm{ ist eine lokale Extremstelle}
	\quad \stackrel{\not\Leftarrow}{\Rightarrow} \quad
	f'(x_0) = 0
\end{align*}
Aus \(f'(x_0)\) folgt nicht direkt die Extremstelle, denn Sattelpunkte sind keine Extremstellen. \\

\noindent
\Beweis ...
\OED

\subsection{Definition des kritischen Punktes}

Ein \(x_0 \in \Rn \) mit \(\nabla f(x_0) = 0\) heißt \textbf{kritischer} oder stationärer Punkt.  

\subsection{Mittelwertsatz}
Sei \(f: G \subset \Rn \rightarrow \R\) differenzierbar und sei \(G\) offen und enthalte die Menge \(\overline{a,b} = \left\{ a,b \in G \mitt  a + t(b-a) : t \in [0,1] \right\}\) (\(a,b\) können durch eine Gerade verbunden werden). Dann:
\begin{align*}
	\exists~ \xi \in (0,1)\quad\mitt\quad f(b) = f(a) + \nabla f(a + \xi(b-a))^\top (b-a) 
\end{align*}
\Bemerkung
\begin{align*}
	& h(t) = a + t(b-a) \quad
	g(t) = f(h(t)) \quad (\textrm{differenzierbar}) \\
	\Rightarrow \quad & \exists~ \xi \in (0,1)\quad\mitt\quad g'(\xi) = \frac{g(1) - g(0)}{1-0}
\end{align*}
\Beweis Definiere \(h(t) = a + t(b-a)\) und \(g: [0,1] \rightarrow \R, g(t) = f(h(t))\) differenzierbar, damit gilt:
\begin{align*}
	\exists~ \xi \in (0,1) \quad\mitt\quad g'(\xi) &= \frac{g(1) - g(0)}{1 - 0} = g(1) - g(0) = f(a) - f(b) \\
	g'(\xi) &= \frac{d}{dt} g(t) \vert_{t = \xi} = \frac{d}{dt} f(h(t)) \vert_{t = \xi} \\
	&\stackrel{\substack{\textrm{Ketten-}\\\textrm{regel}}}{=} f'(h(t))h'(t) \vert_{t = \xi} \\
	&= \nabla f( a + \xi(b-a) )^\top (b-a) = f(a) - f(b) \\
	\Leftrightarrow \quad& f(b) = f(a) + \nabla f( a + \xi(b-a) )^\top (b-a)
\end{align*}
\OED

\subsection{Definition eines Gebiets}

\begin{enumerate}[(i)]
	\item Ein Menge, die wie folgt konstruiert werden kann, heißt \textbf{Polygonzug}:
	\begin{align*}
		\overline{ a_0, ..., a_k} = \bigcup_{j=1}^k \overline{a_{j-1},a_j} \quad\mitt\quad a_0, ..., a_k \in \Rn
	\end{align*}	
	\item Eine Menge \(M \subset \Rn\) heißt \textbf{kurvenweise zusammenhängend} wenn zu beliebigen \(a,b \in M\) eine stetige Funktion \(\gamma : [0,1] \rightarrow M\) mit \(\gamma(0) = a, \gamma(1) = b\) existiert.
	\item Eine Menge \(G \subset \Rn\) heißt \textbf{Gebiet}, wenn \(G\) offen und kurvenweise zusammenhängend ist.
\end{enumerate}


\subsection{Bemerkungen zu Gebieten}

\begin{enumerate}[(i)]
	\item Ein Gebiet \(G\) entspricht einem offenen Intervall \( (a,b) \subset \R\) im Eindimensionalen: Der Rand ist nicht dabei, es hat keine Inseln.
	\item Man kann zeigen, dass es reicht, wenn \(a,b \in G\) mit einem Polygonzug verbunden werden kann.
\end{enumerate}
	
\subsection{Satz}

Sei \(G \subset \Rn\) ein Gebiet, \(G \neq \varnothing\), und \(f : G \rightarrow \R\) differenzierbar, dann gilt:
\begin{align*}
	f(x) = \textrm{konst.} \quad\Leftrightarrow\quad \nabla f(x) = 0 \quad \forall~ x \in G
\end{align*}

\Beweis ...
\OED

\subsection{Definition partieller Ableitungen \(r\)'ter Ordnung}

Für \(f : A \subset \Rn \rightarrow \Rm \) definiert man (wenn diese auch existieren) induktiv für \(x_0 \in A\) und \(k_1, ..., k_r \in \left\{ 1, ..., n \right\} \) die partiellen Ableitungen \(r\)'ter Ordnung als:
\begin{align*}
	\frac{\partial^n}{\partial x_{k_1} \hdots \partial x_{k_r} } f(x_0) = f_{x_{k_1} \hdots x_{k_r}} = 
	\left\{ \begin{array}{ll}
		f(x_0) & r = 0 \\
		\frac{\partial}{\partial x_{k_1}} f(x_0) & r = 1 \\
		\frac{\partial}{\partial x_{k_1}} \left( \frac{\partial^{r-1}}{\partial x_{k_2} \hdots \partial x_{k_r}} f(x_0) \right) & r > 1
	\end{array} \right.
\end{align*}
Existieren alle Ableitungen \(r\)'ter Ordnung und sind diese zudem stetig, so nennt man die Funktion \(f\) \(r\)-mal stetig differenzierbar: \(f \in C^r(A;\Rm)\).

\subsection{Definition der Hessematrix}
Ist \(f : A \subset \Rn \rightarrow \R\) 2-mal stetig differenzierbar bei \(x_0 \in A\), dann ist die \textbf{Hessematrix} wie folgt definiert:
\begin{align*}
	H_f(x_0) = \left( \begin{array}{ccc}
		f_{x_1,x_1} (x_0) & \hdots & f_{x_1,x_n} (x_0) \\
		\vdots & & \vdots \\
		f_{x_m,x_1} (x_0) & \hdots & f_{x_m,x_n} (x_0)
	\end{array} \right)
\end{align*}

\subsection{Beispiele}
\begin{enumerate}[(i)]
	\item \begin{align*}
		f(x,y) = 2xy^3 + y \log x
	\end{align*}
	\item \begin{align*}
		f(x,y) = \left\{ \begin{array}{ll}
			xy \frac{x^2 - y^2}{x^2 + y^2} & (x,y) \neq (0,0) \\
			0 & (x,y) = (0,0)
		\end{array} \right.
	\end{align*}
	\(\Rightarrow\) Hessematrix ist nicht symmetrisch.
	\item \(A \in \Rnxn, b \in \Rn, c \in \R, Q : \Rn \rightarrow \R\)
	\begin{align*}
		Q(x) &= x^\top A x + b^\top x + c \\
		\nabla Q(x) &= \left( A + A^\top \right)x + b \quad \overbrace{( =  2Ax + b)}^{\textrm{wenn }A\textrm{ sym.}} \\
		H_Q(x) &= A + A^\top \quad \underbrace{( = 2A)}_{\textrm{wenn }A\textrm{ sym.}}
	\end{align*}
	\(Q\) wird eine quadratische Funktion genannt.
\end{enumerate}

\subsection{Satz von Schwarz}
Ist \(f : A \subset \Rn \rightarrow \Rn\) in \(x_0\) 2-mal stetig partielle differenzierbar (\(f \in C^2(A)\)), dann ist \(H_f(x_0) \quad \forall~ x_0 \in A\) symmetrisch und es gilt:
\begin{align*}
	f_{x_l, x_k} (x_0) = \frac{\partial}{\partial x_l \partial x_k} f(x_0) = \frac{\partial}{\partial x_k \partial x_l} f(x_0) = f_{x_k, x_l} (x_0) \quad \forall~ l,k \in \{ 1, ..., k \}
\end{align*}

\subsection{Satz von Taylor mit quadratischem Restglied}
Seien \(a,b \in G \subset \Rn, f \in C^2(G), G\) ein Gebiet, dann:
\begin{align*}
	\exists~ \xi \in \overline{a,b} \quad\mitt\quad f(b) = f(a) + \nabla f(a)^\top (b-a) + \frac{1}{2} (b-a)^\top H_f(\xi)(b-a)
\end{align*}

\Beweis
Definiere \(g(t) = f(h(t))\) mit \(h(t) = a + t(b-a) \quad\Rightarrow\quad g(0) = f(a), g(1) = f(b)\). Bei Funktionen mit einem Skalar, gilt der eindimensionale Taylor mit einer Zwischenstelle \(z \in [0,1]\):
\begin{align*}
	\Rightarrow \quad \underbrace{g(1)}_{f(b)} &= \underbrace{g(0)}_{f(a)} + 
	\underbrace{g'(0)(1-0)}_{\substack{
		g'(t) = \frac{d}{dt} f(h(t)) \\
		= f'(h(t))h'(t) \\
		= \nabla f(a + t(b-a))^\top (b-a) \\
		= (b-a)^\top \nabla f(a + t(b-a)) 
	}} + 
	\underbrace{\frac{1}{2} g''(z)(1-0)^2}_{
		g''(t) = ... = (b-a)^\top H_f(a + t(b-a))(b-a)
	} \\
	&= f(a) + \nabla f(a)^\top (b-a) + \frac{1}{2} (b-a)^\top H_f(\underbrace{\xi}_{\xi = a + t(b-a)})(b-a)
\end{align*}
\OED

\subsection{Definition von Definitheit}
Sei \(A \in \Rnxn\) symmetrisch (\(A = A^\top\)):
\begin{enumerate}[a.~]
	\item Die durch \(Q_A(x) = x^\top A x\) definierte Funktion \(Q: \Rn \rightarrow \R\) heißt quadratische Form von \(A\).
	\item Die Matrix \(A\) und ihre quadratische Form \(Q_A\) heißen:
	\begin{enumerate}[(i)]
		\item \textbf{positiv definit}, wenn
		\begin{align*}
			Q_A(x) = x^\top A x > 0 \quad \forall~ x \in \Rn \mitt x \neq 0
		\end{align*}
		\textbf{negativ definit}, wenn
		\begin{align*}
			Q_A(x) = x^\top A x < 0 \quad \forall~ x \in \Rn \mitt x \neq 0
		\end{align*}
		oder kurz \textbf{definit} falls die Matrix \(A\) positiv oder negativ definit ist.
		\item \textbf{semi definit} falls die Matrix \(A\) 
		positiv semi definit oder (negativ semi definit) ist:
		\begin{align*}
			Q_A(x) = x^\top A x \stackrel{(\leqslant)}{\geqslant} 0 \quad \forall~ x \in \Rn \mitt x \neq 0
		\end{align*}
		\item \textbf{indefinit}, wenn ein \(x_1, x_2 \in \Rn\) existieren mit:
		\begin{align*}
			\underbrace{x_1^\top A x_1}_{Q_A(x_1)} < 0
			\quad \textrm{und} \quad 
			\underbrace{x_2^\top A x_2}_{Q_A(x_2)} > 0
		\end{align*}
	\end{enumerate}
\end{enumerate}

\subsection{Beispiele}
\begin{enumerate}[(i)]
	\item \(A = \left( \begin{array}{cc}
		1 & 0 \\
		0 & 1
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		-1 & 0 \\
		0 & -1
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		1 & 0 \\
		0 & -1
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		\lambda_1 & 0 \\
		0 & \lambda_2
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		a & b \\
		c & d
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{ccc}
		a & b & 0 \\
		b & c & 0 \\
		0 & 0 & d
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		2 & 1 \\
		1 & 2
	\end{array} \right) \)
\end{enumerate}

\subsection{Satz zum Hauptminorenkriterium}
Sei \(A = \left( \begin{array}{ccc}
		a_{11} & \hdots & a_{1n} \\
		\vdots & & \vdots \\
		a_{n1} & \hdots & a_{nn}
	\end{array} \right) \in \Rnxn\) symmetrisch,\\ 
	dann ist der \(k\)'te Hauptminor definiert als:
\(
	D_k = \det \underbrace{\left( \begin{array}{ccc}
		a_{11} & \hdots & a_{1k} \\
		\vdots & & \vdots \\
		a_{k1} & \hdots & a_{kk}
	\end{array} \right)}_{k \times k \textrm{ Teilmatrix oben links}}
\)\\
Für die Hauptminoren \(D_1, ..., D_n\) gilt:
\begin{enumerate}[a.~]
	\item \(A\) ist positiv definit \(\quad\Leftrightarrow\quad D_1 > 0, D_2 > 0, ..., D_n > 0\) alle Hauptminoren sind positiv
	\item \(A\) ist negativ definit \(\quad\Leftrightarrow\quad D_1 < 0, D_2 > 0, D_3 < 0, ...\) oder \( D_k = \left\{ \begin{array}{ll}
		< 0 & k \textrm{ ungerade} \\
		> 0 & k \textrm{ gerade}	
	\end{array} \right. \)
	\item \begin{enumerate}[(i)]
		\item \(D_k < 0\) mit \(k\) gerade \(\quad\Rightarrow\quad A\) ist indefinit
		\item \(D_k < 0 < D_l\) mit \(k,l\) ungerade \(\quad\Rightarrow\quad A\) ist indefinit
	\end{enumerate}
\end{enumerate}

\subsubsection*{Beispiele}
\begin{enumerate}[(i)]
	\item \(A = \left( \begin{array}{cc}
		1 & 0 \\
		0 & 1
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		-1 & 0 \\
		0 & -1
	\end{array} \right) \)
	\item \(A = \left( \begin{array}{cc}
		1 & 0 \\
		0 & -1
	\end{array} \right) \)
\end{enumerate}

\subsection{Satz über die hinreichenden Bedingungen für lokale Extremstellen}
Sei \(f \in C^2(U)\) in einer Umgebung \(U\) um \(x_0\) und gilt \(\nabla f(x_0) = 0\) sowie:
\begin{enumerate}[(i)]
	\item \(H_f(x_0)\) ist positiv definit \(\quad\Rightarrow\quad x_0\) ist eine lokale Minimalstelle.
	\item \(H_f(x_0)\) ist negativ definit \(\quad\Rightarrow\quad x_0\) ist eine lokale Maximalstelle.
\end{enumerate}

\Beweis
o.B.d.A nur für (i), denn (ii) folgt analog mit gedrehtem Ungleichungszeichen.\\
Sei \(U = U_\varepsilon(x_0)\) eine \(\varepsilon\)-Umgebung um den Punkt \(x_0 \in \Rn\):
\begin{align*}
	\textrm{Sei } f \in C^2(U) 
	&\Rightarrow H_f \in C^2(U,\Rnxn) \textrm{ mit allen Komponenten stetig} \\
	&\Rightarrow \tilde{g}:\Rn \rightarrow \R, \tilde{g}(x) = (x - x_0)^\top H_f(x) (x - x_0) \textrm{ ist stetig} \\
	&\Rightarrow g(x) = (x - x_0)^\top H_f(h(x)) (x - x_0) \textrm{ ist stetig} \\
	\textrm{ ist }H_f(x_0)\textrm{ pos. def.} 
	&\Rightarrow (x-x_0)^\top H_f(x_0) (x-x_0) > 0 \textrm{ für } x \neq x_0 \\
	&\Rightarrow (x-x_0)^\top H_f(h(x_0)) (x-x_0) > 0 \textrm{ falls }z(x_0)\textrm{ nahe genug bei }x_0	
\end{align*}
Sei \(h(x_0) = x_0 + \xi(x - x_0)\) dann gilt:
\begin{align*}
	f(x) = f(x_0) + 
	\underbrace{
		\underbrace{
			\nabla f(x_0)^\top
		}_{=0}
		(x-x_0)
	}_{=0}		
	+
	\underbrace{
		\frac{1}{2}(x-x_0)^\top
		\underbrace{
			H_f(x_0 + \xi(x - x_0))
		}_{\textrm{pos. def. in } U_\varepsilon(x_0)}
		(x-x_0)
	}_{> 0 ~ \forall x \in U_\varepsilon(x_0)}
	\geqslant f(x_0)
\end{align*}
\OED

\subsection{Definition der Sattelpunkte}
Sei \(U = U_\varepsilon(x_0), f \in C^2(U), \nabla f(x_0) = 0, H_f(x_0)\) indefinit, dann besitzt die Funktion \(f\) bei \(x_0\) einen \textbf{Sattelpunkt}.\\

\Bemerkung \(\forall~ \varepsilon > 0\) gilt:
\begin{align*}
	\exists~ x_1, x_2 \in U_\varepsilon(x_0) \mitt f(x_1) > f(x_0) \textrm{ \underline{und} } f(x_2) < f(x_0)
\end{align*}

\subsection{Satz für den Fall \(n=2\)}
Ist \(f\in C^2(U)\) für eine Umgebung \(U\) von \(x_0 = \left(\begin{array}{c}
	a \\ b
\end{array}\right)\in\R^2\) gilt weiter \(f_x(a,b)=f_y(a,b)=0\), dann ist \(x_0\):
\begin{enumerate}[(i)]
	\item eine lokale \textbf{Minimal}stelle, wenn \\
	\(f_{xx}(a,b) > 0\) (erster Hauptminor \(D_1\)) \underline{und}\\
	 \(f_{xx}(a,b) f_{yy}(a,b) - 2(f_{xy}(a,b))^2 > 0\) (zweiter Hauptminor \(D_2\))
	\item eine lokale \textbf{Maximal}stelle, wenn \\
	\(f_{xx}(a,b) < 0\) (erster Hauptminor \(D_1\)) \underline{und}\\
	 \(f_{xx}(a,b) f_{yy}(a,b) - 2(f_{xy}(a,b))^2 > 0\) (zweiter Hauptminor \(D_2\))
	 \item ein \textbf{Sattelpunkt}, wenn \\
	\(f_{xx}(a,b) < 0\) (erster Hauptminor \(D_1\)) \underline{oder}\\
	 \(f_{xx}(a,b) f_{yy}(a,b) - 2(f_{xy}(a,b))^2 < 0\) (zweiter Hauptminor \(D_2\))
\end{enumerate}

\subsection{Beispiel}
Sei \(f(x,y,z) = x^2 + xy + y^2 - \cos z \in C^2(\R^2)\):
\begin{align*}
	\nabla f(x,y,z) = \left( \begin{array}{c}
		2x + y \\
		x + 2y \\
		\sin z
	\end{array} \right) \stackrel{!}{=} 0
\end{align*}

\section{Extremstellen unter Nebenbedingungen\\
und implizite Funktionen}

\textit{Bisher}: Optimierungsproblem ohne Nebenbedingungen: \(\left\{ \begin{array}{l}
	f(x,y) \rightarrow \min \\
	\left(\begin{array}{c}
		x \\ y
	\end{array}\right) \in \R^2
\end{array}\right.\)\\
Lösbar in drei Schritten:
\begin{enumerate}[1.~]
	\item lokale Minimalstellen bestimmen
	\item untersuche \(f(x,y)\) für \(\left\Vert \left( \begin{array}{c}
		x \\ y	
	\end{array} \right) \right\Vert \rightarrow \infty\) 
	\item vergleiche die Resultate aus 1. und 2.
\end{enumerate}
\Bemerkung aus \(f(x,y) \rightarrow \min\) wird \(-f(x,y) \rightarrow \max\) darum reicht es o.B.d.A. denn Fall \(\rightarrow \min\) zu betrachten.\\

\noindent
\textit{Jetzt}: Optimierungsproblem mit Nebenbedingungen: \(\left\{ \begin{array}{l}
	f(x,y) \rightarrow \min \\
	\left(\begin{array}{c}
		x \\ y
	\end{array}\right) \in A \subset \R^2
\end{array}\right.\)\\
Es ist bekannt, dass wenn \(f \in C(A)\) und \(A \neq \varnothing\) kompakt (abgeschlossen und beschränkt) dann existiert sicher eine Lösung (Satz von Weierstraß: \(f\) stetig und \(A\) kompakt \(\Rightarrow\) es wird ein Minimum (Maximum) angenommen).\\

\noindent
Es sind zwei Fälle möglich:
\begin{enumerate}[(i)]
	\item globale Minimalstelle liegt in \(\mathring{A}\) (im Inneren)
	\item globale Minimalstelle liegt in \(\partial A\) (auf dem Rand)
\end{enumerate}
Wenn zusätzlich \(f \in C^2(A)\) gilt, kann die Minimalstelle wie folgt gefunden werden:
\begin{enumerate}[1.~]
	\item bestimme lokale Minimalstellen mit \(\nabla f(x_0) = 0\) und \(H_f(x_0)\) positiv definit in \(\mathring{A}\)
	\item bestimme lokale Minimalstelle in \(\partial A\)\\
	\Bemerkung Eckpunkte müssen gesondert betrachtet werden, denn die Funktion kann an diesen Stellen nicht differenzierbar sein.
	\item wähle das Minimum aus 1. und 2.
\end{enumerate}

\subsection*{Wiederholung im Eindimensionalen}
Eine Funktion \(f : X\) (Definitionsbereich) \( \rightarrow Y \) (Bildbereich) ist:
\begin{enumerate}[(i)]
	\item \textbf{injektiv}, wenn
	\begin{align*}
		x_1, x_2 \in X \mitt x_1 \neq x_2 \quad\Rightarrow\quad f(x_1) \neq f(x_2)
	\end{align*}
	\textit{Bemerkung}: Von zwei verschiedenen Punkten aus dem Definitionsbereich darf nicht auf den gleichen Punkt im Bildbereich abgebildet werden.
	\item \textbf{surjektiv}, wenn
	\begin{align*}
		\forall~ y \in Y \quad \exists~ x \in X \quad\mitt\quad f(x) = y
	\end{align*}
	\textit{Bemerkung}: Für alle Bildpunkte existiert ein Punkt im Definitionsbereich.
	\item \textbf{bijektiv}, wenn die Funktion \(f\) injektiv und surfjektiv ist.
\end{enumerate}

\subsection*{Beispiel}
Sei \(d : C^1(\R) \rightarrow C(\R)\) eine Funktion mit \(f \mapsto f'\) (Ableitungsoperator für alle einmal stetig differenzierbaren Funktionen). Für diese Funktion \(d\) gilt:
\begin{enumerate}[(i)]
	\item \(d\) ist \underline{nicht} injektiv da:\\
	Seien \(f_1(x) = x, f_2(x) = x + 1\) zwei Funktionen aus \(C^1(\R)\). Für diese gilt: \(f_1 \neq f_2\) aber \(d(f_1) = f_1' = 1 = f_2' = d(f_2)\).
	\item \(d\) ist surjektiv, denn nach dem Hauptsatz der Differential und Integralrechnung gilt: Alle stetigen Funktionen besitzen eine Stammfunktion.
\end{enumerate}

\subsection{Spezialfälle}
\begin{enumerate}[(i)]
	\item \(f\) ist linear und \(f: \Rn \rightarrow \Rm : \quad f(x) = Ax \quad\mitt A \in \Rmxn\) \\
	Im Fall \(m=n\) gilt: \(f\) ist bijektiv \(\Leftrightarrow A\) ist invertierbar.
	\item Allgemeinerer Fall z.b. \(f: [0,\infty) \times [-\pi,\pi) \rightarrow \R^2 : \quad f(r,\varphi) = r \left( \begin{array}{c}
		\cos \varphi \\
		\sin \varphi
	\end{array} \right) \) \\
	\(f\) ist surjektiv aber \underline{nicht} injektiv, denn \( f(0,\varphi) = \left(\begin{array}{c}
		0 \\ 0
	\end{array}\right) \quad \forall~ \varphi \in [-\pi,\pi)\)
\end{enumerate}

\subsection{Bemerkung}
\begin{enumerate}[a.~]
	\item Folgende Aussagen sind äquivalent:
	\begin{enumerate}[(i)]
		\item \(A\) ist invertierbar (oder regulär oder nicht singulär)
		\item \(Ax = b\) besitzt \(\forall~ b \in \Rn\) eine eindeutige Lösung \(x \in \Rn\)
		\item \(\det A \neq 0\)
	\end{enumerate}
	\item Sei \(f:\Rn \rightarrow \Rm \mitt x_0 \in \Rn: \quad f(x) = f(x_0) + A(x - x_0) \quad\mitt \det A \neq 0\)\\
	Die Umkehrfunktion \(f^{-1}\) kann durch 	Äquivalenzumformungen gebildet werden:
	\begin{align*}
		f(x_0) + A(x-x_0) &\stackrel{!}{=} y \\
		\Leftrightarrow\qquad A(x-x_0) &= y - f(x_0) \\
		\Leftrightarrow\qquad x-x_0 &= A^{-1}(y - f(x_0)) \\
		\Leftrightarrow\qquad x &= x_0 + A^{-1}(y - f(x_0)) = f^{-1}(y)
	\end{align*}
	Für die Ableitung der Umkehrfunktion gilt: \(\frac{\partial}{\partial y} f^{-1}(y) = A^{-1}\)
\end{enumerate}
\textit{Kommentar}: Differenzierbare Funktionen sind in einer hinreichend kleinen \(\varepsilon\)-Umgebung im Prinzip linear (nicht ganz korrekt, aber sehr anschaulich).

\subsection{Satz über die Umkehrfunktion}
Sei \(f \in C^1(G;\Rn) \mitt G\subset \Rn\) ein Gebiet, \(x_0 \in G \mitt \det f'(x_0) = \det J_f(x_0) \neq 0\). Dann gilt in einer geeigneten offenen Umgebung \(U\) um \(x_0\), dass
\begin{enumerate}[(i)]
	\item \(V=f(U)\) ist offen (das Bild \(V\) von \(U\) ist offen) und \(\det f'(x) \neq 0 \quad \forall~ x \in U\)
	\item \(f: U \rightarrow V\) ist bijektiv, das heißt: \(\exists~ f^{-1} : V \rightarrow U \) (die Funktion ist lokal invertierbar)
	\Beweis[Beweisidee]
	Da \(f\) stetig differenzierbar ist, gilt:
	\begin{align*}
		f(x) &= f(x_0) + f'(x_0)(x-x_0) + r(x)\Vert x - x_0 \Vert \mitt r(x) \stackrel{x \rightarrow x_0}{\rightarrow} 0 \\
		&\approx f(x_0) + f'(x_0)(x-x_0) \\
		&= f(x_0) + A(x-x_0) \mitt \det A \neq 0
	\end{align*}
	Wenn \(\approx\) ein \(=\) wäre so könnte die Umkehrfunktion \(f^{-1}(y)\) einfach durch Äquivalenzumformungen bestimmt werden \\
	\(\Rightarrow\) In einer hinreichend kleinen \(\varepsilon\)-Umgebung kann \(\approx\) als \(=\) angenommen werden.
	\OED
	\item \( \left( f^{-1} \right)'(y) = \left( f'\left( f^{-1}(y) \right) \right)^{-1} \quad\Leftrightarrow\quad J_{f^{-1}}(y) = J_f^{-1}\left( f^{-1}(y) \right)\)
	\Beweis[Beweisidee] Wenn \(\fum : V \rightarrow U\) existiert, dann ist \(\fum\) auch stetig diff'bar. \\
	\textit{Beispielskizze aus dem Eindimensionalen}:
	\begin{align*}
		f(x) &= e^x, \quad f'(x) = e^x, \quad \exists~ \fum(y) = \log y \\
		\Rightarrow \quad y &= f\left( \fum(y) \right) \\
		\stackrel{\substack{\textrm{Ableiten mit}\\\textrm{Kettenregel}}}{\Rightarrow} \quad
		1 &= f'\left( \fum(y) \right) \cdot (\fum)'(y) \\
		\Rightarrow \quad (\fum)'(y) = \log' y &= \frac{1}{f'\left( \fum(y) \right)} = \frac{1}{e^{\log y}} = \frac{1}{y}
	\end{align*}
	Beispiel übertragen auf den allgemeinen mehrdimensionalen Fall:
	\begin{align*}
		y &= f\left( \fum(y) \right) \\
		\stackrel{\substack{\textrm{Ableiten mit}\\\textrm{Kettenregel}}}{\Rightarrow} \quad
		1 &= \underbrace{f'\left( \fum(y) \right)}_{J_{f'}\left(\fum(y)\right)} \cdot \frac{d}{dy} \fum(y) \\
		\Rightarrow\quad \frac{d}{dy} \fum(y) &= \left( f'\left( \fum(y) \right)\right)^{-1}
	\end{align*}
	\OED
\end{enumerate}

\subsection{Polarkoordinaten}
...

\subsection{Beispiel}
\(f: \R^2 \rightarrow \R^2\) mit \(f(x,y) = \left( \begin{array}{c}
	x - y^2 \\ 2y
\end{array} \right) \)
\begin{align*}
	\Rightarrow f'(x,y) = J_f(x,y) = \left( \begin{array}{cc}
		1 &  -2y \\
		0 & 2
	\end{array} \right) \quad\mitt\quad \det J_f \neq 0
\end{align*}
Direktes Bestimmen der Umkehrfunktion (im Allgemeinen will man dies vermeiden):
\begin{align*}
	\left( \begin{array}{c}
		u \\ v
	\end{array} \right) \stackrel{!}{=} f(x,y)
	\quad&\Leftrightarrow\quad \left( \begin{array}{c}
		u \\ v
	\end{array} \right) = \left( \begin{array}{c}
		x - y^2 \\ 2y
	\end{array} \right)	\\
	&\Rightarrow\quad v = 2y \quad\Leftrightarrow\quad y = \frac{v}{2} \\
	&\Rightarrow\quad u = x - \left( \frac{v}{2} \right)^2 
	\quad\Leftrightarrow\quad x = u + \frac{v^2}{4} \\
	&\Rightarrow\quad
	\left( \begin{array}{c}
		x \\ y
	\end{array} \right) = \left( \begin{array}{c}
		u + \frac{v^2}{4} \\ \frac{v}{2}
	\end{array} \right) = 	
	\fum(u,v)
\end{align*}
Damit gilt für die Ableitung der Umkehrfunktion:
\begin{align*}
	\left( \fum(u,v) \right)' = J_{\fum} (u,v) = \left( \begin{array}{cc}
		1 & \frac{v}{2} \\
		0 & \frac{1}{2}
	\end{array} \right)
\end{align*}
Alternativ mit dem Satz über die Umkehrfunktion:
\begin{align*}
	\left( f^{-1} \right)'(u,v) = \left( f'\left( f^{-1}(u,v) \right) \right)^{-1} = J_f^{-1}\left( u + \frac{v^2}{4}, \frac{v}{2} \right) = \left( \begin{array}{cc}
		1 & -v \\
		0 & 2
	\end{array} \right)^{-1}
	\stackrel{\substack{
		\textrm{Inv. mit}\\
		\textrm{Gauß best.}
	}}{=} \left( \begin{array}{cc}
		1 & \frac{v}{2} \\
		0 & \frac{1}{2}
	\end{array} \right)
\end{align*}

\subsection{Kugelkoordinaten}
Sei \(f: \R^3 \rightarrow \R^3\)
\begin{align*}
	f(r,\varphi,\theta) = \left( \begin{array}{c}
		r \cos\varphi \cos\theta \\
		r \sin\varphi \cos\theta \\
		r \sin\theta
	\end{array} \right) = \left( \begin{array}{c}
		x \\ y \\ z
	\end{array} \right)
\end{align*}

\subsection{Korollar: Gebietstreue}
Ist \(G \subset \Rn\) offen und sei \(f: G \rightarrow \Rn\) eine Funktion mit \(f \in C^1(G;\Rn)\), dann ist \(f(G)\) offen. Ist \(G\) außerdem ein Gebiet, so ist \(f(G)\) auch ein Gebiet.\\
\textit{Fazit}: Für \(\fum\) kann man \(\tilde{G} = f(G)\) definieren und \(\fum : \tilde{G} \rightarrow \Rn\) betrachten. Dabei hat \(\tilde{G}\) die gleichen Eigenschaften wie \(G\).

\subsection{Definition impliziter Funktionen}
Sei \(g: \Rmn \rightarrow \Rm\) mit \(n,m \in \N\) eine Funktion und sei
\begin{align*}
	x = \left( \begin{array}{c}
		x_1 \\ \vdots \\ x_n
	\end{array} \right) \in \Rn, \quad
	y = \left( \begin{array}{c}
		y_1 \\ \vdots \\ y_m
	\end{array} \right) \in \Rm, \quad
	b = \left( \begin{array}{c}
		b_1 \\ \vdots \\ b_m
	\end{array} \right) \in \Rm \textrm{ konstant}
\end{align*}
Man betrachte die Gleichung
\begin{align*}
	g(x,y) = \left( \begin{array}{c}
		g_1(x_1, ..., x_n, y_1, ..., y_m) \\
		\vdots \\
		g_m(x_1, ..., x_n, y_1, ..., y_m)
	\end{array} \right) = \left( \begin{array}{c}
		b_1 \\ \vdots \\ g_m
	\end{array} \right)
\end{align*}
und sagt
\begin{enumerate}[a.~]
	\item die Funktion \(g\) ist bei \(\left(\begin{array}{c} x_0 \\ y_0 \end{array} \right) \) \textbf{lokal nach \(y\) auflösbar}, wenn eine Funktion \(f\) in der Umgebung von \(\left(\begin{array}{c} x_0 \\ y_0 \end{array} \right) \) existiert mit:
	\begin{enumerate}[(i)]
		\item \(f(x_0) = y_0\) und
		\item \(g(x, f(x)) = b\)
	\end{enumerate}
	\item \(g\) ist auf \(A \subset \Rn\) \textbf{global nach \(y\) auflösbar}, wenn eine Funktion \(f : A \rightarrow \Rm\)
	\begin{enumerate}[(i)]
		\item existiert und
		\item \(g(x,f(x)) \quad \forall~ x \in A\) gilt
	\end{enumerate}
	\item analog gilt die Definition für auflösbar nach \(x\) mit \(g(f(y),y)\)
\end{enumerate}

\subsection{Beispiel Einheitskreis}
Sei \(g:\Rzwei \rightarrow \R\) (also \(m=n=1\)) mit \(g(x,y) = x^2 + y^2\) und \(b = 1\). Die Funktion \(g\) ist auflösbar bei \(\left( \begin{array}{c}
	x_0 \\ y_0
\end{array} \right)\), wenn \(x_0 \neq 0\) (denn \(y_0^2 = 1\) hat zwei Lösungen) gilt:
\begin{align*}
	\textrm{Fall } y_0 > 0 &: \quad f_{>0}(x) = y = \sqrt{1 - x^2} \\
	\textrm{Fall } y_0 < 0 &: \quad f_{<0}(x) = y = -\sqrt{1 - x^2}
\end{align*}


\subsection{Hauptsatz über implizite Funktionen}
Seien \(x_0 \in \Rn, y,b \in \Rm\) für eine offene Umgebung \(G\) um \(\left( \begin{array}{c}
	x_0 \\ y_0
\end{array} \right)\) und sei \(g \in C^1(G;\Rm)\) (stetig diff'bar). Gilt weiter \(g(x_0,y_0) = b\) und \(\det g_y(x_0,y_0) \neq 0\) so existiert eine offene Umgebung \(U_0\) von \(x_0\) und \(V_0\) von \(y_0\), so dass gilt:
\begin{enumerate}[(i)]
	\item \(\det g_y(x,y) \neq 0 \quad \forall~ x \in X_0, \forall~ y \in Y_0\)
	\item die Gleichung \(g(x,y) = b\) besitzt eine \textbf{eindeutig bestimmte Auflösung}: \\
	\(f: U_0 \rightarrow V_0\) nach \(y\) mit \(f(x_0) = y_0\) und \(g(x,f(x)) = b \quad \forall~ x \in U_0\)\\
	außerdem ist diese Funktion \(f\) differenzierbar und es gilt: \\
	\(f'(x) = -\left( g_y\left( x_0, f(x_0) \right) \right)^{-1} g_x\left( x_0, f(x_0) \right) = -\left( g_y\left( x_0, y_0 \right) \right)^{-1} g_x\left( x_0, y_0 \right) \)
	\item ist \(g \in C^r(G;\Rm)\) mit \(r \geqslant 2\) so ist \(f \in C^r(U_0;\Rm)\) und die höheren Ableitungen werden durch weiteres ableiten von \(f'\) in (ii) bestimmt.
\end{enumerate}
\Bemerkung
\begin{align*}
	g: \R^{m+n} \rightarrow \Rm \quad&\mitt\quad
	x = \left( \begin{array}{c}
		x_1 \\ \vdots x_n
	\end{array} \right) \in \Rn, \quad
	y = \left( \begin{array}{c}
		y_1 \\ \vdots y_m
	\end{array} \right) \in \Rm \\
	(x,y) \mapsto g(x,y) &= 
	\left( \begin{array}{c}
		g_1(x,y) \\ \vdots \\ g_m(x,y)
	\end{array} \right) = 
	\left( \begin{array}{c}
		g_1(x_1, ..., x_n, y_1, ..., y_m) \\
		\vdots \\
		g_m(x_1, ..., x_n, y_1, ..., y_m)
	\end{array} \right) \\
	g' = \frac{\partial}{\partial(x,y)}= J_g &= \left( \begin{array}{cccccc}
		\frac{\partial}{\partial x_1} g_1 &
		\hdots &
		\frac{\partial}{\partial x_n} g_1 &
		\frac{\partial}{\partial y_1} g_1 &
		\hdots & 
		\frac{\partial}{\partial y_m} g_1 \\
		\vdots & & \vdots & \vdots & & \vdots \\
		\frac{\partial}{\partial x_1} g_m &
		\hdots &
		\frac{\partial}{\partial x_n} g_m &
		\frac{\partial}{\partial y_1} g_m &
		\hdots & 
		\frac{\partial}{\partial y_m} g_m \\
	\end{array} \right) \in \R^{m \times (n+m)} \\
	&= \left( \begin{array}{ccc}
		\frac{\partial}{\partial x} g &
		&
		\frac{\partial}{\partial y} g
	\end{array} \right)
\end{align*}

\Beweis[Beweisidee]
Im Spezialfall, dass die Funktion \(g\) linear ist gilt:
\(
	g(x,y) = A \left( \begin{array}{c}
		x \\ y
	\end{array} \right)
\)\\
Dabei besteht die Matrix \(A \in \R^{m \times (m+n)}\) aus zwei Teilmatrizen \(X \in \Rmxn, Y \in \Rmxm\) also gilt:
\begin{align*}
	g(x,y) = \left( \begin{array}{cc}
		X & Y
	\end{array} \right) \left( \begin{array}{c}
		x \\ y
	\end{array} \right) = Xx + Yy \quad\mitt\quad
	\frac{\partial}{\partial x} g = X, \quad \frac{\partial}{\partial y} g = Y
\end{align*}
Ist die Funktion \(g\) differenzierbar, so ist sie in einer hinreichend kleinen Umgebung näherungsweise linear, also gilt:
\begin{align*}
	g(x,y) = b \quad&\Leftrightarrow\quad Xx + Yy = b \\
	\quad&\Leftrightarrow\quad Yy = b - Xx
	\quad\stackrel{\det Y \neq 0}{=} y = Y^{-1}(b-Xx) = Y^{-1}b - Y^{-1}Xx = f(x) \\
	&\Rightarrow\quad f'(x) = -Y^{-1} X = -(g_y)^{-1} g_x
\end{align*}
\OED
\Bemerkung für den Fall \(m=n=1\) \\
Es gilt \(g(x,f(x)) = b\) für \(x \in U_0\) mit \(g:\Rzwei \rightarrow \R, f:\R \rightarrow \R, b \in \R\) konstant \\
Setze \(h(x) = g(x,f(x))\) mit \(h: \R \rightarrow \R\) also muss \(h(x) = b, \forall x \in U_0\) gelten. Da \(b\) konstant ist, gilt für die Ableitung \(h'(x) = 0\).
\begin{align*}
	h'(x) &\stackrel{\substack{\textrm{Ketten-}\\\textrm{regel}}}{=}
	g'(x,f(x)) \left( \begin{array}{c}
		x \\ f(x)
	\end{array} \right)' = 
	\nabla g (x,f(x))^\top \left( \begin{array}{c}
		1 \\ f'(x)	
	\end{array} \right) \\
	&= \left( \begin{array}{cc}
		g_x(x,f(x)) & g_y(x,f(x))
	\end{array} \right) \left( \begin{array}{c}
		1 \\ f(x)
	\end{array} \right) =
	g_x(x,f(x)) + g_y(x,f(x)) f'(x) = 0 \\
	&\stackrel{g_y(x,f(x))\neq 0}{\Rightarrow} f'(x) = - \frac{g_x(x,f(x)}{g_y(x,f(x))}
	\quad\stackrel{f(x_0)=y_0}{\Rightarrow}\quad - \frac{g_x(x_0,y_0)}{g_y(x_0,y_0)} = f'(x_0)
\end{align*}

\subsection{Lokale Extremstellen unter Nebenbedingungen}
Seien \(f,g_1,...,g_m : G \subset \Rn \rightarrow \R\) mit \(G\) offen gegeben, sowie \(b_1, ..., b_m \in \R\). Dann nennt man \(x_0 \in G\) ein lokales Minimum (Maximum) unter den Nebenbedingungen \(g_1(x) = b_1, ..., g_m(x) = b_m\) wen es eine offene Umgebung \(U \subset G\) von \(x_0\) gibt mit:
\begin{align*}
	f(x) \stackrel{(\leqslant)}{\geqslant} f(x_0) \quad
	\forall~ x \in U \mitt g(x) = b
\end{align*}


\subsection{Satz von Lagrange}
\textbf{Notwendige} Bedingung für Extremstellen unter Nebenbedingungen.\\
Seien \(f,g_1, ..., g_m \in C^1(U)\) für eine offene Umgebung \(U\) von \(x_0 \in \Rn\) und seien \(b_1, ..., b_m \in \R\) (\(b \in \Rm\)). Ist \(x_0 \in U\) eine lokale Extremstelle unter der Nebenbedingung \(g_1(x_0)=b_1, ..., g_m(x_0)=b_m\) und sind die Gradienten \(\nabla g_1(x_0), ..., \nabla g_m(x_0)\) linear unabhängig also \(\det\left( \nabla g_1(x_0), ..., \nabla g_m(x_0) \right) \neq 0\), dann existieren die Konstanten \(\lambda_1, ..., \lambda_m \in \R\) (Lagrange-Multiplikatoren) mit:
\begin{align*}
	\nabla f(x_0) + \underbrace{
		\lambda_1 \nabla g_1(x_0) + ... + \lambda_m \nabla g_m(x_0)
		}_{
			\underbrace{
				\left( \begin{array}{ccc}
					\nabla g_1(x_0) & \hdots & \nabla g_m(x_0)
				\end{array} \right)
			}_{J_g^\top}
			\left( \begin{array}{c}
				\lambda_1 \\
				\vdots \\
				\lambda_m
			\end{array} \right)
		} = 0
\end{align*}
\Bemerkung Der Satz von Lagrange enthält nur eine \textbf{notwendige} Bedingung: Es kann also Punkte geben mit \(\nabla f(x_0) + \lambda \nabla g(x_0) = 0\) die keine Extremstelle sind (z.b. Sattelpunkte). Der Satz liefert also nur Kandidaten, welche dann durch einsetzen in die Funktion \(f\) weiter untersucht werden müssen.\\

\Bemerkung Anschaulich bedeutet die Bedingung \(\nabla f(x_0) + \lambda \nabla g(x_0) = 0\), dass die Gradienten beider Funktionen im Punkt \(x_0\) in die gleiche (oder entgegengesetzte) Richtung schauen müssen.

\Beweis für den Fall \(n=2, m=1\) \\
\(f,g : U \subset \Rzwei \rightarrow \R, b \in \R\) und sei \(\left(\begin{array}{c}
	x_0 \\ y_0
\end{array} \right) \) eine lokale Extremstelle unter der Nebenbedingung \(g(x_0,y_0) = b\). Außerdem sei \(\nabla g(x_0,y_0) \) linear unabhängig (im Fall \(n=2, m=1\) bedeutet dies: nicht der Nullvektor).
\begin{align*}
	\nabla g(x_0,y_0) &= \left( \begin{array}{c}
		g_x(x_0,y_0) \\
		g_y(x_0,y_0)
	\end{array} \right) \\
	&\Rightarrow \quad
	g_x(x_0,y_0) \neq 0 \textrm{ oder } g_y(x_0,y_0) \neq 0
	\stackrel{\textrm{o.B.d.A.}}{\Rightarrow} g_y(x_0,y_) \neq 0 \\
	&\Rightarrow\quad
	\exists \textrm{ eine lokale Auflösung }h\textrm{ nach }y \\
	&\quad\quad h:U_0 \subset \R \rightarrow \R \mitt h(x_0) = y_0 \textrm{ und } g(x,h(x)) = b 
\end{align*}
Sei nun \(\hat{f}(x) = f(x,h(x)) \mitt \hat{f} : U_0 \subset \R \rightarrow \R\) und betrachte \(\hat{f}(x) \rightarrow \min/\max\):
\begin{align*}
	0 \stackrel{!}{=} \hat{f}'(x) = \frac{d}{dx} f(x,h(x)) 
	&\stackrel{\substack{\textrm{Ketten-}\\\textrm{regel}}}{=} \nabla f(x,h(x))^\top \cdot \left( \begin{array}{c} 1 \\ h'(x) \end{array} \right) \\
	&= 
	\left( \begin{array}{cc}
		f_x(x,h(x)) &
		f_y(x,h(x)) 
	\end{array} \right) \left( \begin{array}{c}
		1 \\ h'(x)
	\end{array} \right) \\
	&= f_x(x,h(x)) + f_y(x,h(x)) h'(x)
\end{align*}
Nach dem Hauptsatz über implizite Funktionen gilt \(h'(x) = -\frac{g_x(x,h(x))}{g_y(x,h(x))}\), damit gilt weiter:
\begin{align*}
	0 \stackrel{!}{=} f_x(x,h(x)) - f_y(x,h(x)) \frac{g_x(x,h(x))}{g_y(x,h(x))}
\end{align*}
Bei \(x_0\) gilt ja gerade \(h(x_0) = y_0)\):
\begin{align*}
	0 \stackrel{!}{=} f_x(x_0,y_0) - f_y(x_0,y_0) \frac{g_x(x_0,y_0)}{g_y(x_0,y_0)} = f_x(x_0,y_0) g_y(x_0,y_0) - f_y(x_0,y_0) g_x(x_0,y_0) 
\end{align*}
Also sind die Gradienten \(\nabla f, \nabla g\) linear abhängig.
\OED

\subsection{Bespiele}
\begin{enumerate}[a.~]
	\item \( \left\{ \begin{array}{l}
		f(x,y) = x+y \rightarrow \min/\max \\
		g(x,y) = x^2 + y^2 = b = 1
	\end{array} \right. \)
	\begin{enumerate}[(i)]
		\item Die Nebenbedingung \(g(x,y) = b\) beschreibt eine kompakte (beschränkt und abgeschlossene) Menge 
		\(B = \left\{ \left( \begin{array}{c} x \\ y \end{array} \right) \mitt x^2 + y^2 = 1 \right\}\) und da \(f\) stetig ist gilt: \\
		\(\stackrel{\substack{\textrm{Satz von}\\\textrm{Weierstraß}}}{\Rightarrow} \exists~ x_m, x_M \in B \mitt f(x_m) \leqslant f(x) \leqslant f(x_M) \quad \forall~ x \in B\) \\
		(Die Funktion \(f\) nimmt auf \(B\) ein Minimum und ein Maximum an.)
		\item Für ein \(x_0\) (also \(x_m\) oder \(x_M\)) muss gelten, dass: \\
		\( \exists~ \lambda \in \R \mitt \nabla f(x_0) + \lambda \nabla g(x_0) = 0\)\\
		Man erhält also eine Menge \(\tilde{B} \subset B\) welche die Lagrange-Bedingung erfüllen:
		\begin{align*}
			&\nabla g(x,y) = \left( \begin{array}{c}
				2x \\ 2y
			\end{array} \right),  
			\nabla f(x,y) = \left( \begin{array}{c}
				1 \\ 1			
			\end{array} \right) \\
			& \nabla f(x,y) + \lambda \nabla g(x,y) \stackrel{!}{=} 0 \\
			\Leftrightarrow\quad& \left( \begin{array}{c}
				1 \\ 1
			\end{array} \right) + \lambda
			\left( \begin{array}{c}
				2x \\ 2y
			\end{array} \right) = 
			\left( \begin{array}{c}
				0 \\ 0
			\end{array} \right) \\
			\Leftrightarrow\quad& \left. \begin{array}{l}
				\lambda \cdot 2x = -1 \\
				\lambda \cdot 2y = -1
			\end{array} \right\{ \begin{array}{l}
				2 \textrm{ Gleichungen mit }3\textrm{ Unbekannten} \\
				\Rightarrow 1\textrm{ Freiheitsgrad }(\textrm{durch }\lambda \textrm{ beschrieben})
			\end{array}\\
			\textrm{Fall } x \neq 0, y \neq 0 \quad& 
			- \frac{1}{2x} = \lambda = - \frac{1}{2y} 
			\quad\Rightarrow\quad x=y \\
			\textrm{Fall } x = 0, y \neq 0 \quad& 2\cdot 0 \cdot \lambda = -1 \Rightarrow 0 = -1 \Rightarrow \textrm{Widerspruch, Fall nicht möglich} \\
			&\Rightarrow \textrm{dasselbe gilt für die Fälle } x \neq 0, y = 0 \textrm{ und } x = 0, y = 0 \\
			\stackrel{\substack{
				\textrm{Einetzen in die} \\
				\textrm{Nebenbedingung}
			}}{\Rightarrow}\quad& b = 1 = g(x,y) = x^2 + y^2 \stackrel{x=y}{\Rightarrow} 1 = x^2 + x^2 \Leftrightarrow x_{1,2} = \pm \frac{1}{\sqrt{2}} \\
			\Rightarrow\quad&
			\tilde{B} = \left\{ \left( \begin{array}{c}
				\frac{1}{\sqrt{2}} \\
				\frac{1}{\sqrt{2}}
			\end{array} \right),
			\left( \begin{array}{c}
				-\frac{1}{\sqrt{2}} \\
				-\frac{1}{\sqrt{2}}
			\end{array} \right)
			\right\} \\
			\stackrel{
				\substack{
					\textrm{Satz von}\\
					\textrm{Weierstraß}
				}
			}{\Rightarrow}\quad& x_m, x_M \in \tilde{B}
		\end{align*}
		\item Prüfen der Elemente aus \(\tilde{B}\):
		\begin{align*}
			&f(\left(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right) = \frac{1}{\sqrt{2}} + \frac{1}{\sqrt{2}} = \sqrt{2} \quad\Rightarrow\quad \max \\
			&f(\left(-\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}\right) = -\frac{1}{\sqrt{2}} - \frac{1}{\sqrt{2}} = -\sqrt{2} \quad\Rightarrow\quad \min			
		\end{align*}
	\end{enumerate}
	\item \( \left\{ \begin{array}{l}
		f(x,y) = x^2+y^2 \rightarrow \min/\max \\
		g(x,y) = x + y = b = 1
	\end{array} \right. \) \\
	Die Menge \(B = \left\{ \left( \begin{array}{c} x \\ y \end{array} \right) \mitt x + y = 1 \right\}\) ist nicht kompakt, darum gilt hier der Satz von Weierstraß nicht! In diesem konkreten Fall existiert kein Maximum.
\end{enumerate}

\end{document}








